Jo Wood says…
>	Thanks Robert for bringing this topic up. I think of all the aspects of "visualization" that we have yet to fully realise, this is the most under-researched, at least by academic infovis researchers.
>	
>	I would take issue with several of those aspects you list as limitations of sonification. You say we cannot 'zoom in' with sound. I think there are strong aural analogies with zooming through the careful use of frequency filtering and volume. This is done masterfully by Mike Figgis in his 2000 film Timecode  - https://en.wikipedia.org/wiki/Timecode_(film) - that shows 4 simultaneous perspectives in a split screen but uses audio zooming to move our attention between each of those 4 parallel stories in a serial fashion. And as an aside, this is a film well worth experiencing at the cinema as it makes use of surround sound to control the audio spatially - another property under-researched from a visualization perspective.
>	
>	The relationship between sound and real-time linear narrative is an interesting one. Yes, certainly an autio stream is delivered over time, but then so is a static visualization (we need a certain sustained period of time to explore a static image before it becomes meaningful to us). Like animation, sound may well most easily support linear temporal narrative, but it need not be limited to that. Just ask any composer whether their compositions are necessarily linear. And in a visualization context interaction gives us the possibility of 'rewind', 'reverse', 'filter', 'selection', 'highlight', 'zoom' in an audio context. 
>	
>	In reading your article I found myself listening to Isao Hashimoto's excellent 1945-1998 piece while continuing to read and scrolling the visual off the page. It highlights something audio offers - the ability to process audio and visual signals in parallel and somewhat independently. Again something that is woefully under-researched in the context of our discipline (but not others).
>	
>	But perhaps the point in your article I would disagree with most is "The Problem" that audio typically does not scale well in the same way as the visual. Yes, those explosion sounds were months long if scaled to the animation timeline, but then look at the size of their visual symbols on the world map. Multiple scalings of symbols is something we do all the time when interpreting visualizations. Even the dot map technique you mention commonly enlarges dots in comparison to their 'true' scale on a typical map (and let's not forget that even giving a point value some areal expression as a pixel on the screen is still a geometric abstraction). I don't see this as a problem, and certainly not one that is unique to sound.
>	
>	Personally I am more optimistic that the richness and expressiveness of sonification has untapped potential for infovis. Perhaps we should be collaborating more with the artists, film makers, audio engineers and musicians who spend a lifetime exploring what sound has to offer us.
>	
>	Jo

<a href="http://kylehailey.com" rel="nofollow noopener" target="_blank">Kyle Hailey</a> says…
>	For streaming data like performance monitoring signification could add extra information, like an extra dimension. Here's an article from a few years ago 
>	http://philadelphia.cbslocal.com/2013/12/25/493270/
>	the video doesn't seem available anymore :(
>	Was thinking over the intervening 4 years there would be more done with data sonification.
>	here some interesting discussion https://cds.cern.ch/record/2142696
>	but for large seems of data, sound could help the consumer more rapidly distinguish different scenarios.

Clément V. says…
>	I thank you Jo for your enriching comment. Your last point on the scale of symbols vs the scale of the time scale is really helpful. I think it highlights the fact that data points have to be perceptible, at the cost of consistency.
>	Maybe one way to reconcile Robert with this inconsistency is to consider that sonification brings more emotion than a viz, and more than being perceptible, data points must have emotional resonance. Finally the weeks or month each note/sound represents (in a share scale) can be seen as the impact than and not the event.

<a href="http://extraordinarysquares.blogspot.com" rel="nofollow noopener" target="_blank">JohnG</a> says…
>	Here's the sonification of stormtroopers in the galaxy, from our friends at the BBC: http://www.bbc.co.uk/programmes/p039nljx
>	
>	Enjoy!

<a href="http://gravatar.com/sahmeepee" rel="nofollow noopener" target="_blank">sahmeepee</a> says…
>	This is a good mix of audio and visual in the depiction of activity in a rat's hippocampus as it completes a maze exercise:
>	
>	https://youtu.be/lfNVv0A8QvI
>	
>	The sonic dimension gives you a sense of the pace of activity much more clearly than the image does as it's not easy to represent overlapping dots on a 2d plane. With different sounds for the different regions it's possible to bring out variation in type as well as rate. As you point out in your article, one of the reasons this works well is that it's displaying realtime information rather than attempting to compress time.
>	
>	I can imagine a number of situations where it would be useful to represent data which is not ordinarily detectable as an overlay on top of video or, as in this case, on a video-graphic combination. In some ways we are already used to this, e.g. the overlayed heart-beat sound in a tense horror-film scene, but we just don't consider it sonification because it is art rather than science.
>	
>	Thanks for a thought-provoking post...
>	
>	S

<a href="http://www.dumkydewilde.nl" rel="nofollow noopener" target="_blank">Dumky</a> says…
>	Fascinating read and some nice examples! I agree that the audio timeline can get to crowded quickly, but I was wondering what your perspective is on practical tools that use sonification. The two that come to my mind are heart rate monitors (in hospitals) and the blips we use with parking sensors in cars. I think their power comes from the fact that there's a lack of visibility that is compensated by audio (we can't look at all the heart rate monitor all the time, and we can't see the other cars clearly when parking). Of course the amount of data that is sonified is minimal in these cases, but I think it shows that audio representations of information in some cases do a better job than the visual representation. I'd say that is in part because of the sense of urgency they create (it's really hard to ignore a continuing high pitched sound compared to an image).
